{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63eb2ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue because it absorbs blue light. When sunlight reaches Earth, it hits its atmosphere, which then absorbs some of that light. This process continues until the light reaches our eyes.\n",
      "\n",
      "In summary, the sky appears blue because it absorbs blue light from the sun.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from ollama import Client\n",
    "\n",
    "client = Client(host='http://jupyter.weburban.com:10434')\n",
    "\n",
    "# Use list to see what models you have pulled.\n",
    "client.list()\n",
    "\n",
    "response = client.chat(model='qwen:0.5b', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])\n",
    "\n",
    "print(response['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3410dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'models': [{'name': 'flanT5:latest', 'model': 'flanT5:latest', 'modified_at': '2024-10-18T09:30:47.189735154Z', 'size': 496288729, 'digest': '7a929ef5596adbc4f8a090da61da9c23e02c8cacce0c547059ddc9765cda8eb3', 'details': {'parent_model': '', 'format': 'gguf', 'family': 't5', 'families': ['t5'], 'parameter_size': '247.58M', 'quantization_level': 'F16'}}, {'name': 'flanT5_Q8:latest', 'model': 'flanT5_Q8:latest', 'modified_at': '2024-10-18T01:48:56.267189427Z', 'size': 310495610, 'digest': 'f3d524247f7e302770f085c1e52f0b913ab336d5a1c75edcafe654b3b8625120', 'details': {'parent_model': '', 'format': 'gguf', 'family': 't5', 'families': ['t5'], 'parameter_size': '247.58M', 'quantization_level': 'Q8_0'}}, {'name': 'phi3.5:latest', 'model': 'phi3.5:latest', 'modified_at': '2024-10-18T01:41:23.843218919Z', 'size': 2176178843, 'digest': '61819fb370a3c1a9be6694869331e5f85f867a079e9271d66cb223acb81d04ba', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'phi3', 'families': ['phi3'], 'parameter_size': '3.8B', 'quantization_level': 'Q4_0'}}, {'name': 'phi:latest', 'model': 'phi:latest', 'modified_at': '2024-10-18T01:40:36.235231383Z', 'size': 1602463378, 'digest': 'e2fd6321a5fe6bb3ac8a4e6f1cf04477fd2dea2924cf53237a995387e152ee9c', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'phi2', 'families': ['phi2'], 'parameter_size': '3B', 'quantization_level': 'Q4_0'}}, {'name': 'gemma2:2b', 'model': 'gemma2:2b', 'modified_at': '2024-10-18T01:39:44.799247654Z', 'size': 1629518495, 'digest': '8ccf136fdd5298f3ffe2d69862750ea7fb56555fa4d5b18c04e3fa4d82ee09d7', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'gemma2', 'families': ['gemma2'], 'parameter_size': '2.6B', 'quantization_level': 'Q4_0'}}, {'name': 'gemma:2b', 'model': 'gemma:2b', 'modified_at': '2024-10-18T01:39:10.735260179Z', 'size': 1678456656, 'digest': 'b50d6c999e592ae4f79acae23b4feaefbdfceaa7cd366df2610e3072c052a160', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'gemma', 'families': ['gemma'], 'parameter_size': '3B', 'quantization_level': 'Q4_0'}}, {'name': 'stablelm2:latest', 'model': 'stablelm2:latest', 'modified_at': '2024-10-18T01:38:33.107275771Z', 'size': 982790462, 'digest': '714a6116cffa8b415b52c62a7a2d09ba6227ed733baa0025c937a36aee5504f3', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'stablelm', 'families': ['stablelm'], 'parameter_size': '2B', 'quantization_level': 'Q4_0'}}, {'name': 'orca-mini:latest', 'model': 'orca-mini:latest', 'modified_at': '2024-10-18T01:38:06.511287973Z', 'size': 1979947443, 'digest': '2dbd9f439647093cf773c325b0b3081a11f1b1426d61dee8b946f8f6555a1755', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'llama', 'families': None, 'parameter_size': '3B', 'quantization_level': 'Q4_0'}}, {'name': 'tinydolphin:latest', 'model': 'tinydolphin:latest', 'modified_at': '2024-10-18T01:37:23.151310125Z', 'size': 636743607, 'digest': '0f9dd11f824c7f9a881c9e663d71c1bb0ed0b1d76dd21f6c679f7193c3be7308', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'llama', 'families': ['llama'], 'parameter_size': '1B', 'quantization_level': 'Q4_0'}}, {'name': 'tinyllama:latest', 'model': 'tinyllama:latest', 'modified_at': '2024-10-18T01:37:01.427322338Z', 'size': 637700138, 'digest': '2644915ede352ea7bdfaff0bfac0be74c719d5d5202acb63a6fb095b52f394a4', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'llama', 'families': ['llama'], 'parameter_size': '1B', 'quantization_level': 'Q4_0'}}, {'name': 'qwen2:1.5b', 'model': 'qwen2:1.5b', 'modified_at': '2024-10-18T01:36:38.611336019Z', 'size': 934964102, 'digest': 'f6daf2b25194025ae2d5288f2afd041997ce48116807a3b612c1a96b09bec03a', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'qwen2', 'families': ['qwen2'], 'parameter_size': '1.5B', 'quantization_level': 'Q4_0'}}, {'name': 'qwen2:0.5b', 'model': 'qwen2:0.5b', 'modified_at': '2024-10-18T01:36:17.955349187Z', 'size': 352164041, 'digest': '6f48b936a09f7743c7dd30e72fdb14cba296bc5861902e4d0c387e8fb5050b39', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'qwen2', 'families': ['qwen2'], 'parameter_size': '494.03M', 'quantization_level': 'Q4_0'}}, {'name': 'qwen:1.8b', 'model': 'qwen:1.8b', 'modified_at': '2024-10-18T01:36:17.071349768Z', 'size': 1120243281, 'digest': 'b6e8ec2e7126ea21d1817e28ad69a2bebdd5547a9af223fbb927054dc66fc4ce', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'qwen2', 'families': ['qwen2'], 'parameter_size': '2B', 'quantization_level': 'Q4_0'}}, {'name': 'qwen:0.5b', 'model': 'qwen:0.5b', 'modified_at': '2024-10-18T01:35:52.631366389Z', 'size': 394998579, 'digest': 'b5dc5e784f2a3ee1582373093acf69a2f4e2ac1710b253a001712b86a61f88bb', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'qwen2', 'families': ['qwen2'], 'parameter_size': '620M', 'quantization_level': 'Q4_0'}}, {'name': 'qwen2.5:0.5b', 'model': 'qwen2.5:0.5b', 'modified_at': '2024-10-17T06:40:37.514909596Z', 'size': 397821319, 'digest': 'a8b0c51577010a279d933d14c2a8ab4b268079d44c5c8830c0a93900f1827c67', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'qwen2', 'families': ['qwen2'], 'parameter_size': '494.03M', 'quantization_level': 'Q4_K_M'}}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\amirs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\Users\\amirs\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Response:\n",
      "**Relevant Text:**\n",
      "Design an experiment involving 200 high school students, randomly assigned to two groups: one with AI-driven personalized learning tools and the other with traditional instructional methods. Both groups will undergo the same curriculum but with different learning supports.\n",
      "\n",
      "The hypothesis is that using AI-driven personalized learning tools increases student engagement and improves academic performance in high school mathematics. The experiment involves comparing the two groups based on the statistical analysis of academic performance and engagement scores before and after the intervention period.\n",
      "\n",
      "**Extracted Hypothesis:**\n",
      "**Hypothesis:** Using AI-driven personalized learning tools increases student engagement and improves academic performance in high school mathematics.\n",
      "\n",
      "**Extracted Experiment:**\n",
      "- **Group A (AI-driven personalization):** 200 high school students using an AI platform to provide personalized learning recommendations based on their performance, learning style, and pace.\n",
      "- **Group B (traditional instruction):** 200 high school students following the traditional instructional methods.\n",
      "\n",
      "The hypothesis is tested by comparing academic performance scores before and after the intervention period. Data analysis will be conducted to assess statistical significance between the two groups, revealing whether the use of AI-driven personalized learning tools leads to better academic outcomes compared to traditional instruction.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from ollama import Client\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain import PromptTemplate\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "\n",
    "# Initialize the LLM client (ensure the host URL is correct)\n",
    "client = Client(host='http://jupyter.weburban.com:10434')\n",
    "\n",
    "# Use list to see available models\n",
    "print(client.list())\n",
    "\n",
    "# Function to load text files\n",
    "def load_text_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='replace') as file:\n",
    "        return file.read()\n",
    "\n",
    "# Load example hypothesis and new document\n",
    "example_text_path = \"Data/Gen2Doc.txt\"\n",
    "example_hypothesis_path = \"Data/Gen2Hypo.txt\"\n",
    "example_experiment_path = \"Data/Gen2Ex.txt\"\n",
    "new_text_path = \"Data/blood_cells.txt\"\n",
    "\n",
    "example_text = load_text_file(example_text_path)\n",
    "example_hypothesis = load_text_file(example_hypothesis_path)\n",
    "example_experiment = load_text_file(example_experiment_path)\n",
    "new_text = load_text_file(new_text_path)\n",
    "\n",
    "# Split the new document into chunks using NLTK sentence tokenization\n",
    "nltk.download('punkt')\n",
    "chunks = sent_tokenize(new_text)\n",
    "\n",
    "# Initialize a BERT model for sentence embeddings\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "# Convert the document's sentences into embeddings\n",
    "sentence_embeddings = model.encode(chunks, convert_to_tensor=False)\n",
    "\n",
    "# Define the query\n",
    "query = \"\"\"\n",
    "Extract relevant text for hypothesis and experiment extraction from the following document content.\n",
    "\n",
    "**Definition of Hypothesis:**\n",
    "A research hypothesis is a concise statement about the expected result of an experiment or project, often derived from prior research and observations.\n",
    "\n",
    "**Definition of Experiment:**\n",
    "An experiment to prove a hypothesis is a structured and controlled procedure designed to test whether a hypothesis is true or false. In an experiment, specific variables are manipulated, while others are kept constant, allowing researchers to observe and measure the effects of the changes.\n",
    "\"\"\"\n",
    "\n",
    "# Convert the query into an embedding\n",
    "query_embedding = model.encode(query, convert_to_tensor=False)\n",
    "\n",
    "# Compute similarity scores between the query and sentence embeddings\n",
    "similarity_scores = cosine_similarity([query_embedding], sentence_embeddings)[0]\n",
    "\n",
    "# Retrieve the top-k most relevant chunks (adjust k as needed)\n",
    "top_k = 10  # Number of chunks to retrieve\n",
    "top_k_indices = similarity_scores.argsort()[-top_k:][::-1]\n",
    "\n",
    "# Retrieve the relevant chunks and add some context windows\n",
    "relevant_chunks = []\n",
    "for idx in top_k_indices:\n",
    "    start = max(0, idx - 1)  # Add previous sentence as context\n",
    "    end = min(len(chunks), idx + 2)  # Add next sentence as context\n",
    "    relevant_chunks.extend(chunks[start:end])\n",
    "\n",
    "# Combine relevant chunks into one text\n",
    "main_relevant_text = \" \".join(relevant_chunks)\n",
    "\n",
    "# Prepare the refined prompt with clearer instructions and chain-of-thought guidance\n",
    "prompt_template = PromptTemplate(\n",
    "    template=f\"\"\"\n",
    "    The following is an example of a text with its corresponding hypothesis and experiment. This is provided to illustrate the structure, but you are required to focus **only** on the new relevant text provided below.\n",
    "\n",
    "    **Example (for reference only):**\n",
    "    \n",
    "    **Example Text:**\n",
    "    {example_text}\n",
    "    \n",
    "    **Example Hypothesis:**\n",
    "    {example_hypothesis}\n",
    "    \n",
    "    **Example Experiment:**\n",
    "    {example_experiment}\n",
    "    \n",
    "    **Definitions:**\n",
    "    - A **Hypothesis** is a concise statement about the expected result of an experiment or project.\n",
    "    - An **Experiment** is a structured and controlled procedure designed to test whether a hypothesis is true or false.\n",
    "    \n",
    "    Now, analyze the following **Relevant Text** and extract the hypothesis and experiment **from this new text only**:\n",
    "\n",
    "    **Relevant Text:**\n",
    "    {main_relevant_text}\n",
    "\n",
    "    **Step-by-step reasoning**:\n",
    "    1. Read the relevant text carefully and ignore the example text provided above.\n",
    "    2. Look for statements in the new text that propose a relationship between variables or an expected result—this is the hypothesis.\n",
    "    3. Then, find any statements that describe how the hypothesis is tested or validated—this will be the experiment.\n",
    "    4. Write the hypothesis in 1-2 sentences and the experiment in 2-3 sentences.\n",
    "\n",
    "\n",
    "    Please ensure you are only using the main_relevant_text to extract the hypothesis and experiment.\n",
    "    \n",
    "    **Extracted Hypothesis:**\n",
    "    - Provide the hypothesis from the relevant text in 1-2 concise sentences.\n",
    "    \n",
    "    **Extracted Experiment:**\n",
    "    - Provide a detailed experimental procedure from the relevant text in 2-3 sentences.\n",
    "    \"\"\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Fill the prompt with the relevant text\n",
    "filled_prompt = prompt_template.format(text=main_relevant_text)\n",
    "\n",
    "# Use the updated Ollama client to invoke the LLM\n",
    "response = client.chat(model='qwen2.5:0.5b', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': filled_prompt,\n",
    "    }\n",
    "])\n",
    "\n",
    "# Print the generated hypothesis and experiment\n",
    "print(\"\\nGenerated Response:\")\n",
    "print(response['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cb36ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'models': [{'name': 'flanT5:latest', 'model': 'flanT5:latest', 'modified_at': '2024-10-18T09:30:47.189735154Z', 'size': 496288729, 'digest': '7a929ef5596adbc4f8a090da61da9c23e02c8cacce0c547059ddc9765cda8eb3', 'details': {'parent_model': '', 'format': 'gguf', 'family': 't5', 'families': ['t5'], 'parameter_size': '247.58M', 'quantization_level': 'F16'}}, {'name': 'flanT5_Q8:latest', 'model': 'flanT5_Q8:latest', 'modified_at': '2024-10-18T01:48:56.267189427Z', 'size': 310495610, 'digest': 'f3d524247f7e302770f085c1e52f0b913ab336d5a1c75edcafe654b3b8625120', 'details': {'parent_model': '', 'format': 'gguf', 'family': 't5', 'families': ['t5'], 'parameter_size': '247.58M', 'quantization_level': 'Q8_0'}}, {'name': 'phi3.5:latest', 'model': 'phi3.5:latest', 'modified_at': '2024-10-18T01:41:23.843218919Z', 'size': 2176178843, 'digest': '61819fb370a3c1a9be6694869331e5f85f867a079e9271d66cb223acb81d04ba', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'phi3', 'families': ['phi3'], 'parameter_size': '3.8B', 'quantization_level': 'Q4_0'}}, {'name': 'phi:latest', 'model': 'phi:latest', 'modified_at': '2024-10-18T01:40:36.235231383Z', 'size': 1602463378, 'digest': 'e2fd6321a5fe6bb3ac8a4e6f1cf04477fd2dea2924cf53237a995387e152ee9c', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'phi2', 'families': ['phi2'], 'parameter_size': '3B', 'quantization_level': 'Q4_0'}}, {'name': 'gemma2:2b', 'model': 'gemma2:2b', 'modified_at': '2024-10-18T01:39:44.799247654Z', 'size': 1629518495, 'digest': '8ccf136fdd5298f3ffe2d69862750ea7fb56555fa4d5b18c04e3fa4d82ee09d7', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'gemma2', 'families': ['gemma2'], 'parameter_size': '2.6B', 'quantization_level': 'Q4_0'}}, {'name': 'gemma:2b', 'model': 'gemma:2b', 'modified_at': '2024-10-18T01:39:10.735260179Z', 'size': 1678456656, 'digest': 'b50d6c999e592ae4f79acae23b4feaefbdfceaa7cd366df2610e3072c052a160', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'gemma', 'families': ['gemma'], 'parameter_size': '3B', 'quantization_level': 'Q4_0'}}, {'name': 'stablelm2:latest', 'model': 'stablelm2:latest', 'modified_at': '2024-10-18T01:38:33.107275771Z', 'size': 982790462, 'digest': '714a6116cffa8b415b52c62a7a2d09ba6227ed733baa0025c937a36aee5504f3', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'stablelm', 'families': ['stablelm'], 'parameter_size': '2B', 'quantization_level': 'Q4_0'}}, {'name': 'orca-mini:latest', 'model': 'orca-mini:latest', 'modified_at': '2024-10-18T01:38:06.511287973Z', 'size': 1979947443, 'digest': '2dbd9f439647093cf773c325b0b3081a11f1b1426d61dee8b946f8f6555a1755', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'llama', 'families': None, 'parameter_size': '3B', 'quantization_level': 'Q4_0'}}, {'name': 'tinydolphin:latest', 'model': 'tinydolphin:latest', 'modified_at': '2024-10-18T01:37:23.151310125Z', 'size': 636743607, 'digest': '0f9dd11f824c7f9a881c9e663d71c1bb0ed0b1d76dd21f6c679f7193c3be7308', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'llama', 'families': ['llama'], 'parameter_size': '1B', 'quantization_level': 'Q4_0'}}, {'name': 'tinyllama:latest', 'model': 'tinyllama:latest', 'modified_at': '2024-10-18T01:37:01.427322338Z', 'size': 637700138, 'digest': '2644915ede352ea7bdfaff0bfac0be74c719d5d5202acb63a6fb095b52f394a4', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'llama', 'families': ['llama'], 'parameter_size': '1B', 'quantization_level': 'Q4_0'}}, {'name': 'qwen2:1.5b', 'model': 'qwen2:1.5b', 'modified_at': '2024-10-18T01:36:38.611336019Z', 'size': 934964102, 'digest': 'f6daf2b25194025ae2d5288f2afd041997ce48116807a3b612c1a96b09bec03a', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'qwen2', 'families': ['qwen2'], 'parameter_size': '1.5B', 'quantization_level': 'Q4_0'}}, {'name': 'qwen:1.8b', 'model': 'qwen:1.8b', 'modified_at': '2024-10-18T01:36:17.071349768Z', 'size': 1120243281, 'digest': 'b6e8ec2e7126ea21d1817e28ad69a2bebdd5547a9af223fbb927054dc66fc4ce', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'qwen2', 'families': ['qwen2'], 'parameter_size': '2B', 'quantization_level': 'Q4_0'}}, {'name': 'qwen2:0.5b', 'model': 'qwen2:0.5b', 'modified_at': '2024-10-18T01:36:17.955349187Z', 'size': 352164041, 'digest': '6f48b936a09f7743c7dd30e72fdb14cba296bc5861902e4d0c387e8fb5050b39', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'qwen2', 'families': ['qwen2'], 'parameter_size': '494.03M', 'quantization_level': 'Q4_0'}}, {'name': 'qwen:0.5b', 'model': 'qwen:0.5b', 'modified_at': '2024-10-18T01:35:52.631366389Z', 'size': 394998579, 'digest': 'b5dc5e784f2a3ee1582373093acf69a2f4e2ac1710b253a001712b86a61f88bb', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'qwen2', 'families': ['qwen2'], 'parameter_size': '620M', 'quantization_level': 'Q4_0'}}, {'name': 'qwen2.5:0.5b', 'model': 'qwen2.5:0.5b', 'modified_at': '2024-10-17T06:40:37.514909596Z', 'size': 397821319, 'digest': 'a8b0c51577010a279d933d14c2a8ab4b268079d44c5c8830c0a93900f1827c67', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'qwen2', 'families': ['qwen2'], 'parameter_size': '494.03M', 'quantization_level': 'Q4_K_M'}}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\amirs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\Users\\amirs\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Response:\n",
      "### Extracted Hypothesis:\n",
      "A randomized controlled trial comparing two methods of personalized learning to assess their impact on student engagement and academic performance in high school mathematics.\n",
      "\n",
      "### Extracted Experiment:\n",
      "The experiment involves randomly assigning 600 high school students (200 in each group) to either an AI-driven personalized learning group or a traditional instructional method group. Both groups follow the same math curriculum but receive different learning supports, including access to AI tools and more structured instruction. Pre- and post-intervention academic performance in mathematics is measured using standardized tests, while engagement is assessed through surveys and classroom observation.\n",
      "\n",
      "Over the course of a semester, the AI group demonstrates a marked improvement in test scores compared to the control group. Data are statistically significant if p < 0.05. Participation rates among students in the AI group are higher than those in the traditional method group. Observations reveal that students using AI tools actively participate more in class discussions and complete assignments with greater enthusiasm.\n",
      "\n",
      "### New Task Instructions:\n",
      "1. Analyze the relevant text provided.\n",
      "2. Extract a hypothesis from this text.\n",
      "3. Based on the extracted hypothesis, propose an experiment to test it.\n",
      "4. Provide both the hypothesis in 1-2 sentences and the experiment in 2-3 concise sentences.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from ollama import Client\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain import PromptTemplate\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "\n",
    "# Initialize the LLM client (ensure the host URL is correct)\n",
    "client = Client(host='http://jupyter.weburban.com:10434')\n",
    "\n",
    "# Use list to see available models\n",
    "print(client.list())\n",
    "\n",
    "# Function to load text files\n",
    "def load_text_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='replace') as file:\n",
    "        return file.read()\n",
    "\n",
    "# Load example hypothesis and new document\n",
    "example_text_path = \"Data/Gen2Doc.txt\"\n",
    "example_hypothesis_path = \"Data/Gen2Hypo.txt\"\n",
    "example_experiment_path = \"Data/Gen2Ex.txt\"\n",
    "new_text_path = \"Data/blood_cells.txt\"\n",
    "\n",
    "example_text = load_text_file(example_text_path)\n",
    "example_hypothesis = load_text_file(example_hypothesis_path)\n",
    "example_experiment = load_text_file(example_experiment_path)\n",
    "new_text = load_text_file(new_text_path)\n",
    "\n",
    "# Split the new document into chunks using NLTK sentence tokenization\n",
    "nltk.download('punkt')\n",
    "chunks = sent_tokenize(new_text)\n",
    "\n",
    "# Initialize a BERT model for sentence embeddings\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "# Convert the document's sentences into embeddings\n",
    "sentence_embeddings = model.encode(chunks, convert_to_tensor=False)\n",
    "\n",
    "# Define the query\n",
    "query = \"\"\"\n",
    "Extract relevant text for hypothesis and experiment extraction from the following document content.\n",
    "\n",
    "**Definition of Hypothesis:**\n",
    "A research hypothesis is a concise statement about the expected result of an experiment or project, often derived from prior research and observations.\n",
    "\n",
    "**Definition of Experiment:**\n",
    "An experiment to prove a hypothesis is a structured and controlled procedure designed to test whether a hypothesis is true or false. In an experiment, specific variables are manipulated, while others are kept constant, allowing researchers to observe and measure the effects of the changes.\n",
    "\"\"\"\n",
    "\n",
    "# Convert the query into an embedding\n",
    "query_embedding = model.encode(query, convert_to_tensor=False)\n",
    "\n",
    "# Compute similarity scores between the query and sentence embeddings\n",
    "similarity_scores = cosine_similarity([query_embedding], sentence_embeddings)[0]\n",
    "\n",
    "# Retrieve the top-k most relevant chunks (adjust k as needed)\n",
    "top_k = 10  # Number of chunks to retrieve\n",
    "top_k_indices = similarity_scores.argsort()[-top_k:][::-1]\n",
    "\n",
    "# Retrieve the relevant chunks and add some context windows\n",
    "relevant_chunks = []\n",
    "for idx in top_k_indices:\n",
    "    start = max(0, idx - 1)  # Add previous sentence as context\n",
    "    end = min(len(chunks), idx + 2)  # Add next sentence as context\n",
    "    relevant_chunks.extend(chunks[start:end])\n",
    "\n",
    "# Combine relevant chunks into one text\n",
    "main_relevant_text = \" \".join(relevant_chunks)\n",
    "\n",
    "# Prepare the refined prompt with clearer instructions and chain-of-thought guidance\n",
    "prompt_template = PromptTemplate(\n",
    "    template=f\"\"\"\n",
    "    Below is an example that illustrates how to extract a hypothesis and experiment from a document.\n",
    "    Please focus only on the **Relevant Text** provided after the example, ignoring the example for your extraction task.\n",
    "    \n",
    "    **Example (for reference only):**\n",
    "    ---\n",
    "    **Example Text:**\n",
    "    {example_text}\n",
    "\n",
    "    **Example Hypothesis:**\n",
    "    {example_hypothesis}\n",
    "\n",
    "    **Example Experiment:**\n",
    "    {example_experiment}\n",
    "    ---\n",
    "    \n",
    "    **New Task Instructions:**\n",
    "    Now, analyze the following **Relevant Text** and extract the hypothesis and experiment based only on this new text:\n",
    "\n",
    "    **Relevant Text:**\n",
    "    {main_relevant_text}\n",
    "\n",
    "    **Step-by-step reasoning**:\n",
    "    1. Ignore the example text.\n",
    "    2. Look for a hypothesis in the relevant text, which suggests a relationship between variables or an expected outcome.\n",
    "    3. Find any experiment that tests this hypothesis in the relevant text.\n",
    "    4. Provide the hypothesis in 1-2 sentences and the experiment in 2-3 sentences.\n",
    "\n",
    "    **Extracted Hypothesis:**\n",
    "    - Provide the hypothesis from the relevant text in 1-2 concise sentences.\n",
    "\n",
    "    **Extracted Experiment:**\n",
    "    - Provide the experiment in 2-3 concise sentences, describing how the hypothesis is tested.\n",
    "    \"\"\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "# Fill the prompt with the relevant text\n",
    "filled_prompt = prompt_template.format(text=main_relevant_text)\n",
    "\n",
    "# Use the updated Ollama client to invoke the LLM without the temperature argument\n",
    "response = client.chat(model='qwen2.5:0.5b', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': filled_prompt,\n",
    "    }\n",
    "])\n",
    "\n",
    "# Print the generated hypothesis and experiment\n",
    "print(\"\\nGenerated Response:\")\n",
    "print(response['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9ffb8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
