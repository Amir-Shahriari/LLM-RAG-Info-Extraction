{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21b9c82e-7c5e-4929-88ae-bb9b0d747bee",
   "metadata": {},
   "source": [
    "# Project: LLM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e6d20f-a435-40a0-8705-2fd8fa365aac",
   "metadata": {},
   "source": [
    "### 1. Prompt Engineering Approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4734c882-ff97-4a6d-bae4-00fe9def1e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = Ollama(\n",
    "    base_url=\"http://notebooks.weburban.com:12434\", \n",
    "    model=\"tinyllama\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a394652-9417-45b8-ab6f-29d90ab58a69",
   "metadata": {},
   "source": [
    "**Scientific Article Dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15659d0f-d106-4277-b692-f1b485cb3462",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HATHEVENT\\AppData\\Local\\Temp\\ipykernel_13228\\2772987447.py:18: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  llm_chain = LLMChain(\n",
      "C:\\Users\\HATHEVENT\\AppData\\Local\\Temp\\ipykernel_13228\\2772987447.py:28: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  extracted_text = llm_chain.run(text=text_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article provides evidence for a hypothesis that cytokine-secretion activity in T cells is impaired during alloimmunization. Specifically, the author examines the effect of alloimmunity on cytokine secretion using cell line Jurka and animal model Acute Graft-versus-Host Disease (aGvHD) in mice.\n",
      "\n",
      "The study involves experiments on human cells donated from an immunocompromised donor, which has been shown to be a suitable model for acute GVHD. The author examines the effects of alloimmunity by comparing cytokine secretion by Jurka and Jurka cells infected with Acute GVHD mice.\n",
      "\n",
      "The results show that while cytokine secretion is reduced in both cell lines during alloimmunization, the reduction is more significant in the Jurka cells infected with Acute GVHD mice than in Jurka cells infected with normal mice or non-immunocompromised mice. The effect of alloimmunity on cytokine secretion appears to be specific for T cells.\n",
      "\n",
      "Additionally, the study examines the effects of alloimmunization on cytokine production by different cell lines, indicating that T cells are particularly affected during this process.\n",
      "\n",
      "The paper provides valuable evidence for the hypothesis that cytokine-secretion activity in T cells is impaired during alloimmunization, and further supports the use of Jurka cells as a suitable model to investigate this topic.\n"
     ]
    }
   ],
   "source": [
    "# Define a prompt template to extract the experiment element with a clear definition\n",
    "prompt_template = \"\"\"\n",
    "You are an expert in reading scientific texts. An \"Experiment element\" refers to sections of a document that describe how an experiment was conducted, including the materials and methods used, the results obtained, and the discussion of these results.\n",
    "\n",
    "Here is the text:\n",
    "{text}\n",
    "\n",
    "Extracted Experiment Element:\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the prompt template\n",
    "template = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# Create an LLMChain for processing\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=template\n",
    ")\n",
    "\n",
    "# Load the text data\n",
    "with open('Data/blood_cells.txt', 'r') as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "# Run the chain to extract the experiment element\n",
    "extracted_text = llm_chain.run(text=text_data)\n",
    "\n",
    "# Print the extracted experiment element\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc9a9e9-ba26-4c4a-89d7-f27e094f86db",
   "metadata": {},
   "source": [
    "**Technical Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "839c4502-bb61-4b87-9cf6-7784ef9835dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure 4 is an additional experiment element added to the drawing provided by the text material. It's a schematic diagram illustrating the device as described in the text, highlighting the main components and their relationships. The figure shows the device with its housings, coupling arrangements, vibraction sensors, electronic circuits, and associated components arranged within the void. The figure also provides information on the external components (e.g., a baseplate, covering, etc.) that are not included in the original drawing.\n"
     ]
    }
   ],
   "source": [
    "# Define a prompt template to extract the experiment element with a clear definition\n",
    "prompt_template = \"\"\"\n",
    "You are an expert in reading technical documents. An \"Experiment element\" refers to sections of a document that describe the setup, procedures, and results of experiments conducted to test or validate a device or system.\n",
    "\n",
    "Here is the text:\n",
    "{text}\n",
    "\n",
    "Extracted Experiment Element:\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the prompt template\n",
    "template = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# Create an LLMChain for processing\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=template\n",
    ")\n",
    "\n",
    "# Load the text data (replace with actual file content)\n",
    "with open('Data/device.txt', 'r') as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "# Run the chain to extract the experiment element\n",
    "extracted_text = llm_chain.run(text=text_data)\n",
    "\n",
    "# Print the extracted experiment element\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ace5ee-6e36-45d6-b505-78babb1742c6",
   "metadata": {},
   "source": [
    "**Conversations Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b2c1ef9-834d-443a-8939-6c40f5ebbbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person 1: What was the t-test method used in the experiment?\n",
      "\n",
      "Person 2: The t-test is a statistical test that uses a repeated measurement to determine whether there is a significant difference between two groups, measured by differences in means. In our case, we used this test to compare the results of welder techniques on two materials with varying thermal properties.\n",
      "\n",
      "Person 1: That's interesting! So, can you explain how the new technique works?\n",
      "\n",
      "Person 2: Certainly! Our researchers developed a machine learning algorithm that can monitor temperature and adjust the arc length based on material properties during welder operations. This allows for more consistent and accurate results with different materials. We use real-time sensor data to adjust the arc length in real time, which helps reduce heat input variations.\n",
      "\n",
      "Person 1: That's impressive! How long did it take to conduct the t-test on these materials?\n",
      "\n",
      "Person 2: The t-test took about a month to complete due to the complexity of the data and the need for multiple comparisons. However, our research team worked closely with the statistical software company to optimize the analysis method for this type of data. We believe that by combining the t-test with statistical techniques we will be able to get more consistent results in future experiments.\n",
      "\n",
      "Person 1: Interesting! So, can you tell me how many joints were analyzed?\n",
      "\n",
      "Person 2: The experiment involved 50 random joints from each material. We randomly assigned 23 pairs of defect-free joints and 27 pairs with defects.\n",
      "\n",
      "Person 1: That's a pretty large sample size! How did you determine the effect sizes for these results?\n",
      "\n",
      "Person 2: We used the Rand index to determine the degree of agreement between the two groups. The Rand index is a statistical measure that quantifies the overlap in the patterns or characteristics of two groups, which can indicate the similarity of their outcomes. In our case, we found that both welder techniques had a significant effect size on the number of defects per joint, with Technique A having 120 fewer defects than Technique B and Technique B having 45 fewer defects. However, there was variability in the data, which is why we're still conducting additional experiments to get more consistent results.\n",
      "\n",
      "Person 1: Wow, that's pretty impressive! I can see how these techniques could be used in manufacturing or product development.\n"
     ]
    }
   ],
   "source": [
    "# Define a prompt template to extract the experiment element with a clear definition\n",
    "prompt_template = \"\"\"\n",
    "You are an expert in reading technical documents. An \"Experiment element\" refers to sections of a document that describe the setup, procedures, and results of experiments conducted to test or validate a hypothesis, technique, or system.\n",
    "\n",
    "Here is the text:\n",
    "{text}\n",
    "\n",
    "Extracted Experiment Element:\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the prompt template\n",
    "template = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# Create an LLMChain for processing\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=template\n",
    ")\n",
    "\n",
    "# Load the text data (replace with actual file content)\n",
    "with open('Data/dummy.txt', 'r', encoding=\"utf8\") as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "# Run the chain to extract the experiment element\n",
    "extracted_text = llm_chain.run(text=text_data)\n",
    "\n",
    "# Print the extracted experiment element\n",
    "print(extracted_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
