{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "015976fb-39fe-4625-9290-d6e523de5eac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person 1: Hi there, could you please provide us with a detailed explanation of the new welding technique that we recently learned about?\n",
      "\n",
      "Person 2: Sure, I'd be happy to! The new welding technique is based on a cutting-edge approach called Dynamic Controlled Arc Length (DCA), which uses real-time sensor data and machine learning algorithms to adjust the arc length based on material's thermal properties. This allows for more consistent and precise welding with less variation in heat input.\n",
      "\n",
      "Person 3: That sounds promising! Can you elaborate on how this new technique works?\n",
      "\n",
      "Person 2: Sure thing! The Dynamic Controlled Arc Length (DCA) approach involves adjusting the arc length based on a combination of thermal properties and material's temperature profile during welding. It allows for greater consistency in the welder's movement, which reduces the variability in heat input and improves the accuracy of the welds.\n",
      "\n",
      "Person 1: That sounds like something that could really benefit our products. How do you plan to fine-tune this technique to be consistent with our materials?\n",
      "\n",
      "Person 2: We're still in the testing phase for the new welding technique, but we need more data to ensure its effectiveness before making a final decision on its use. Our testing includes real-time sensor measurements of temperature changes during welding, as well as machine learning algorithms that adjust the arc length based on these changes. We plan to monitor and analyze this data continuously to improve the technique's performance over time.\n",
      "\n",
      "Person 3: Sounds promising! Do you have any concrete results to share with us?\n",
      "\n",
      "Person 2: Yes, we do! The new welding technique has shown impressive results in terms of reducing defects and improving consistency of welding. In one particular joint study, the new technique reduced defects by around 62.5%, compared to Technique B, which had around 120 defects per 50 joints (the same number as Technique A).\n",
      "\n",
      "Person 3: That's quite impressive! I can see why this new welding technique could be worth exploring for our products. Is there anything else you'd like to share?\n",
      "\n",
      "Person 2: Sure, we also developed a system that uses real-time sensor data and machine learning algorithms to monitor and adjust the arc length based on thermal properties during welding. The system helps us identify variations in heat input, which allows us to make more consistent welds.\n",
      "\n",
      "Person 3: That's cool! So, are there any limitations or drawbacks to this new technique?\n",
      "\n",
      "Person 2: As with any new technique, there are potential drawbacks and limitations. One of the key challenges is obtaining enough data to accurately analyze and optimize the welder's movements. Another issue is that some welds may not perform as well as others due to a variety of factors such as the material being processed or the specific joint being created.\n",
      "\n",
      "Person 1: That makes sense. Can you provide any further details on how the new welding technique works with materials?\n",
      "\n",
      "Person 2: Sure thing! The new welder is designed to adapt to different materials and welding processes, which is why we've found that it performs well with both austenitic stainless steel and mild steel. The Dynamic Controlled Arc Length (DCA) approach also allows for more precise placement of the weld, which can lead to better alignment and fusion.\n",
      "\n",
      "Person 3: That's great! I think we have a good handle on how this new welding technique works with materials. Thanks for sharing all that information with us today!\n",
      "\n",
      "Person 2: No problem at all! We're always happy to provide you with the latest updates and developments in our industry. Let me know if there's anything else we can help with!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = Ollama(\n",
    "    base_url=\"http://notebooks.weburban.com:12434\",\n",
    "    model=\"tinyllama\"\n",
    ")\n",
    "\n",
    "\n",
    "def load_text_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='replace') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "\n",
    "# Example usage: Load a text file\n",
    "document_content = load_text_file(\"Dummy.txt\")\n",
    "\n",
    "# Prepare the prompt with the document content\n",
    "prompt_template = PromptTemplate(\n",
    "    template=f\"\"\"Given the provided text:\n",
    "{document_content}\n",
    "\n",
    "Please extract and clearly label the **Hypothesis** from the document content.\n",
    "\n",
    "**Definition of Hypothesis**: \n",
    "The hypothesis should be a statement or series of statements that outline (a) the result you aim to achieve, and (b) how and why you believe you can achieve it, informed by your background research.\n",
    "\n",
    "**Format for Response**:\n",
    "Your response should strictly follow the format provided above and include only the hypothesis.\n",
    "\n",
    "Hypothesis:\n",
    "1. [Your hypothesis statement(s) here]\n",
    "\n",
    "Please provide your response in the format specified above. Do not include any dialogues and only provide me with the Hypothesis\n",
    "you have extracted from the document.\n",
    "\"\"\",\n",
    "    input_variables=[\"document\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Fill the prompt template with document content\n",
    "filled_prompt = prompt_template.format(document=document_content)\n",
    "\n",
    "# Invoke the model\n",
    "response = llm.invoke(filled_prompt)\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56c6ebc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amirs\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person 1: Good morning, everyone! I'm excited to introduce our latest product innovation that promises to revolutionize the welder industry. After years of research and testing, we are proud to present this new technique for welding materials commonly used in construction, manufacturing, and other industries. Our goal is to provide a more reliable, faster, and cost-effective alternative to traditional welding methods.\n",
      "\n",
      "Person 2: Our new welder technology uses cutting-edge technology to ensure accurate welding of various metals, including those with thermal shock properties such as cast iron or steel. We have developed a system that utilizes infrared sensors and machine learning algorithms to adjust the arc length based on the material's thermal properties during welding. This allows for consistent and uniform welding results, reducing heat input variations and improving the weld quality.\n",
      "\n",
      "Person 3: We have also incorporated dynamic cutting-edge techniques that adjust the arc length automatically in real-time. These features help to reduce heat input variations and ensure optimal performance during welding, leading to better welds. The system has been tested with a range of materials such as cast iron, steel, and carbon steel, and has shown impressive results with 62.5% reduction in defects when comparing Technique A and Technique B.\n",
      "\n",
      "Person 1: Our new technique is a significant advance in the welder industry, offering faster speeds, higher accuracy, and better reliability than traditional methods. We believe this innovation will revolutionize the welding process for various industries, leading to cost savings while maintaining high-quality results.\n",
      "\n",
      "Person 2: In addition to the improved weld quality, our new technique offers significant cost savings compared to traditional welder methods. With less downtime and a shorter turnaround time, we believe this innovation will be highly sought after by businesses looking to reduce their costs while improving efficiency in manufacturing or construction projects.\n",
      "\n",
      "Person 3: The data shows that our new technique has reduced defects on average by 62.5%, but there's still a lot of variability in the results. We need more data to fully understand the potential impact this innovation could have in industries like manufacturing, construction, and transportation.\n",
      "\n",
      "Person 1: With this new technique, we aim to make a difference in the lives of people around the world. By reducing defects and improving the efficiency of welding processes, our new method will enable more efficient and cost-effective manufacturing or construction projects. We believe that this innovation could change industries for the better while providing significant economic benefits.\n",
      "\n",
      "Person 2: To further solidify our commitment to our customers, we are offering a 50% discount on all purchases until the end of the month. This incentive will help us reach a wider audience and encourage others to invest in this new technology for their own projects.\n",
      "\n",
      "Person 3: Our innovation is still being tested and refined, but we are confident that it has the potential to revolutionize the welding industry. With this new method, we believe we can provide more reliable and cost-effective solutions for various industries while improving efficiency and productivity.\n",
      "\n",
      "In conclusion, our new technique offers significant improvements in weld quality and productivity, while reducing downtime and overhead costs. We invite you to join us as we continue to pursue innovation and deliver better solutions for our customers.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain import PromptTemplate\n",
    "from langchain.schema import Document  \n",
    "from langchain.retrievers import TFIDFRetriever \n",
    "\n",
    "\n",
    "llm = Ollama(\n",
    "    base_url=\"http://notebooks.weburban.com:12434\",\n",
    "    model=\"tinyllama\"\n",
    ")\n",
    "\n",
    "def load_text_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='replace') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "# Example usage: Load a text file\n",
    "document_content = load_text_file(\"Dummy.txt\")\n",
    "\n",
    "# Step 1: Split the document into chunks\n",
    "chunks = document_content.split(\"\\n\\n\")  # Example: splitting by paragraphs\n",
    "\n",
    "# Step 2: Convert chunks to LangChain Document objects\n",
    "documents = [Document(page_content=chunk, metadata={\"id\": str(i)}) for i, chunk in enumerate(chunks)]\n",
    "\n",
    "# Step 3: Initialize the retriever\n",
    "retriever = TFIDFRetriever.from_documents(documents)  # Correct way to initialize with Document objects\n",
    "\n",
    "# Step 4: Retrieve relevant chunks\n",
    "query = \"\"\"Please extract and clearly label the **Hypothesis** from the document content.\n",
    "\n",
    "**Definition of Hypothesis**: \n",
    "The hypothesis should be a statement or series of statements that outline (a) the result you aim to achieve, and (b) how and why you believe you can achieve it, informed by your background research.\n",
    "\n",
    "**Format for Response**:\n",
    "Your response should strictly follow the format provided above and include only the hypothesis.\n",
    "\n",
    "Hypothesis:\n",
    "1. [Your hypothesis statement(s) here]\n",
    "\n",
    "Please provide your response in only a single paragraph in the format specified above and please include the title of the paragraph as \"Hypothesis\".\"\"\"\n",
    "\n",
    "relevant_chunks = retriever.get_relevant_documents(query)  # Retrieve relevant chunks\n",
    "\n",
    "# Combine relevant chunks\n",
    "relevant_text = \" \".join([doc.page_content for doc in relevant_chunks])\n",
    "\n",
    "# Step 5: Prepare the prompt with the retrieved relevant text\n",
    "prompt_template = PromptTemplate(\n",
    "    template=f\"\"\"Given the provided relevant text:\n",
    "{relevant_text}\n",
    "\n",
    "**Definition of Hypothesis**: \n",
    "The hypothesis should be a statement or series of statements that outline (a) the result you aim to achieve, and (b) how and why you believe you can achieve it, informed by your background research.\n",
    "\n",
    "**Format for Response**:\n",
    "Your response should strictly follow the format provided above and include only the hypothesis.\n",
    "\n",
    "Hypothesis:\n",
    "1. [Your hypothesis statement(s) here]\n",
    "\n",
    "Please provide **Hypothesis** of this provided document in only a single paragraph in the format specified above and please include the title of the paragraph as **Hypothesis**.\n",
    "\"\"\",\n",
    "    input_variables=[\"document\"]\n",
    ")\n",
    "\n",
    "# Fill the prompt template with retrieved text\n",
    "filled_prompt = prompt_template.format(document=relevant_text)\n",
    "\n",
    "# Invoke the model\n",
    "response = llm.invoke(filled_prompt)\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae932f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In summary, our study has provided evidence supporting the hypothesis that RBCs have a protective effect on PBMCs against CD4+ and CD8+ cell apoptosis following exposure to an immunosuppressant peptide. The RBCs were found to include both CD4+ and CD8+ cells, with ccRBCs (CD4+ cells only) stimulating the proliferation of T-cells but not oRBCs or ccRBCs, whereas PHA-P alone promoted the expression of two transcription factors and secretion of cytokines. Our results highlight the potential for the RBCs to mitigate the immunotoxicity of peptide stimuli used in cancer therapy, providing a potential target for the development of new anticancer treatments.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain import PromptTemplate\n",
    "from langchain.schema import Document  \n",
    "from langchain.retrievers import TFIDFRetriever \n",
    "\n",
    "\n",
    "llm = Ollama(\n",
    "    base_url=\"http://notebooks.weburban.com:12434\",\n",
    "    model=\"tinyllama\"\n",
    ")\n",
    "\n",
    "def load_text_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='replace') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "# Example usage: Load a text file\n",
    "document_content = load_text_file(\"RedBlood.txt\")\n",
    "\n",
    "# Step 1: Split the document into chunks\n",
    "chunks = document_content.split(\"\\n\\n\")  # Example: splitting by paragraphs\n",
    "\n",
    "# Step 2: Convert chunks to LangChain Document objects\n",
    "documents = [Document(page_content=chunk, metadata={\"id\": str(i)}) for i, chunk in enumerate(chunks)]\n",
    "\n",
    "# Step 3: Initialize the retriever\n",
    "retriever = TFIDFRetriever.from_documents(documents)  # Correct way to initialize with Document objects\n",
    "\n",
    "# Step 4: Retrieve relevant chunks\n",
    "query = \"\"\"Please extract and clearly label the **Hypothesis** from the document content.\n",
    "\n",
    "**Definition of Hypothesis**: \n",
    "The hypothesis should be a statement or series of statements that outline (a) the result you aim to achieve, and (b) how and why you believe you can achieve it, informed by your background research.\n",
    "\"\"\"\n",
    "\n",
    "relevant_chunks = retriever.get_relevant_documents(query)  # Retrieve relevant chunks\n",
    "\n",
    "# Combine relevant chunks\n",
    "relevant_text = \" \".join([doc.page_content for doc in relevant_chunks])\n",
    "\n",
    "# Step 5: Prepare the prompt with the retrieved relevant text\n",
    "prompt_template = PromptTemplate(\n",
    "    template=f\"\"\"Given the provided relevant text:\n",
    "{relevant_text}\n",
    "\n",
    "**Definition of Hypothesis**: \n",
    "The hypothesis should be a statement or series of statements that outline (a) the result you aim to achieve, and (b) how and why you believe you can achieve it, informed by your background research.\n",
    "\n",
    "**Format for Response**:\n",
    "Your response should strictly follow the format provided above and include only the hypothesis.\n",
    "\n",
    "Hypothesis:\n",
    "1. [Your hypothesis statement(s) here]\n",
    "\n",
    "Please provide **Hypothesis** of this provided document in only a single paragraph in the format specified above and include the title of the paragraph as **Hypothesis**.\n",
    "\"\"\",\n",
    "    input_variables=[\"document\"]\n",
    ")\n",
    "\n",
    "# Fill the prompt template with retrieved text\n",
    "filled_prompt = prompt_template.format(document=relevant_text)\n",
    "\n",
    "# Invoke the model\n",
    "response = llm.invoke(filled_prompt)\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a2db7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Device for Collecting Virable Data Comprising: Housing, Coupling Arrangement, Vible Sensor, Electronic Circuit, and Battery Charger\n",
      "\n",
      "Introductory statement: This document provides a detailed description of a device that has the following capabilities:\n",
      "\n",
      "- A housing that has an inner surface defining a void;\n",
      "- A coupling arrangement for coupling the housing to a baseplate;\n",
      "- A vible sensor located in the void and electrically coupled to the coupling arrangement and capable of receiving signals from the sensor and processing them to create virable data.\n",
      "\n",
      "Background research: The device is designed to collect virable data, which refers to data that can be used for scientific research or engineering analysis, while maintaining a low cost. This is achieved by utilizing a vible sensor with an encased housing and coupling arrangement, which allows for easy integration into harsh environments. Furthermore, the battery charging arrangement provides efficient recharge of batteries using an inductive charger.\n",
      "\n",
      "Hypotheis: The hypothesis for achieving this device's capabilities is that by utilizing inductive coupling between the coupling arrangement and the vible sensor, the viable data can be created and processed with ease while minimizing energy waste. Furthermore, recharge of batteries using an inductive battery charger enables efficient recharge of batteries in harsh environments, making the device suitable for use in the mining industry.\n",
      "\n",
      "Explanation: The housing provides protection to the vible sensor, which is encased within it. The coupling arrangement allows the housing and baseplate to be seamlessly attached and disassembled without any adhesives or glues, providing ease of use. Furthermore, the battery charging arrangement ensures efficient recharge of batteries using an inductive charger, minimizing energy waste.\n",
      "\n",
      "Introduction to the device's specifications: The housing is made from Nylon polyamide and has four apertures for coupling the housing to the baseplate. The vible sensor is located within the housing and is electrically coupled to the coupling arrangement. The electronic circuit is arranged on the outside of the housing, where it is protected from damage by the battery. The battery charging arrangement consists of an inductive charger that recharges batteries using an inductive coupling.\n",
      "\n",
      "Hypotheis: By utilizing inductive coupling between the coupling arrangement and vible sensor, the viable data can be created and processed efficiently while minimizing energy waste. Furthermore, by incorporating an inductive charger into the battery charging arrangement, recharge of batteries using a suitable charging method is achieved in harsh environments without any adverse effects on the battery.\n",
      "\n",
      "Conclusion: In conclusion, this device offers viable data collection capabilities while minimizing energy waste and providing efficient recharge of batteries in harsh environmental conditions. It comprises several parts that work together to provide a user-friendly system for collecting virable data.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain import PromptTemplate\n",
    "from langchain.schema import Document  \n",
    "from langchain.retrievers import TFIDFRetriever \n",
    "\n",
    "\n",
    "llm = Ollama(\n",
    "    base_url=\"http://notebooks.weburban.com:12434\",\n",
    "    model=\"tinyllama\"\n",
    ")\n",
    "\n",
    "def load_text_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='replace') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "# Example usage: Load a text file\n",
    "document_content = load_text_file(\"DOMV.txt\")\n",
    "\n",
    "# Step 1: Split the document into chunks\n",
    "chunks = document_content.split(\"\\n\\n\")  # Example: splitting by paragraphs\n",
    "\n",
    "# Step 2: Convert chunks to LangChain Document objects\n",
    "documents = [Document(page_content=chunk, metadata={\"id\": str(i)}) for i, chunk in enumerate(chunks)]\n",
    "\n",
    "# Step 3: Initialize the retriever\n",
    "retriever = TFIDFRetriever.from_documents(documents)  # Correct way to initialize with Document objects\n",
    "\n",
    "# Step 4: Retrieve relevant chunks\n",
    "query = \"\"\"Please extract and clearly label the **Hypothesis** from the document content.\n",
    "\n",
    "**Definition of Hypothesis**: \n",
    "The hypothesis should be a statement or series of statements that outline (a) the result you aim to achieve, and (b) how and why you believe you can achieve it, informed by your background research.\n",
    "\"\"\"\n",
    "\n",
    "relevant_chunks = retriever.get_relevant_documents(query)  # Retrieve relevant chunks\n",
    "\n",
    "# Combine relevant chunks\n",
    "relevant_text = \" \".join([doc.page_content for doc in relevant_chunks])\n",
    "\n",
    "# Step 5: Prepare the prompt with the retrieved relevant text\n",
    "prompt_template = PromptTemplate(\n",
    "    template=f\"\"\"Given the provided relevant text:\n",
    "{relevant_text}\n",
    "\n",
    "**Definition of Hypothesis**: \n",
    "The hypothesis should be a statement or series of statements that outline (a) the result you aim to achieve, and (b) how and why you believe you can achieve it, informed by your background research.\n",
    "\n",
    "**Format for Response**:\n",
    "Your response should strictly follow the format provided above and include only the hypothesis.\n",
    "\n",
    "Hypothesis:\n",
    "1. [Your hypothesis statement(s) here]\n",
    "\n",
    "Please provide **Hypothesis** of this provided document in only a single paragraph in the format specified above and include the title of the paragraph as **Hypothesis**.\n",
    "\"\"\",\n",
    "    input_variables=[\"document\"]\n",
    ")\n",
    "\n",
    "# Fill the prompt template with retrieved text\n",
    "filled_prompt = prompt_template.format(document=relevant_text)\n",
    "\n",
    "# Invoke the model\n",
    "response = llm.invoke(filled_prompt)\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8711fbef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
